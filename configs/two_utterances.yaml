paths:
  input_audio_dir: "./assets/zeroth_v2"
  noise_dir: "./assets/noises"
  output_dir: "./data/augmented_audio_v2"
  label_dir: "./data/labels_v2"
  hf_dataset_dir: "./data/hf_dataset_v2"
  noise_catalog: "./data/noise/noise_catalog.csv"
  noise_resampled_dir: "./data/noise/resampled"
  raw_samples_path: "./data/zeroth_v2/raw_samples_train.jsonl"
  alignment_output_dir: "./data/labels_v2"
  pair_manifest: "./data/zeroth_v2/pairs_train.jsonl"

aligner:
  model_name: "large-v3"
  language: "ko"
  device: "cuda"
  align_model_name: "kresnik/wav2vec2-large-xlsr-korean"
  compute_type: "float16"
  batch_size: 8
  vad_backend: "none"
  diarize: false
  rng_seed: 42

pairing:
  min_utterance_sec: 1.5
  max_utterance_sec: 15.0
  max_length_ratio: 3.0
  allow_cross_split: false
  max_pause_gap_sec: 5.0

synthesis:
  mode: "two_utterances"
  min_gap_sec: 0.5
  insertion_duration_sec:
    min: 1.0
    max: 2.5
  transition_gap_sec:
    default: 2.5
    jitter: 0.5
  crossfade_sec: 0.08
  context_window_sec: 0.75
  target_snr_db: 10.0
  loudness_target_lufs: -23.0
  true_peak_dbfs: -1.0
  insertions_per_file: 1
  rng_seed: 9876
  noise_categories: []

labelling:
  baseline_model_name: "openai/whisper-large-v3"
  transition_token: "<SIL_TRANS>"
  include_silence_token: true

metadata:
  enable_tracking: true
  save_original_segments: true
